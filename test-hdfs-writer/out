17/03/30 15:02:42 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /user/chinmay/test-location
1490866362672 : Starting writer
17/03/30 15:02:42 DEBUG util.Shell: setsid exited with exit code 0
17/03/30 15:02:42 DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
17/03/30 15:02:42 DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
17/03/30 15:02:42 DEBUG lib.MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[GetGroups], type=DEFAULT, always=false, sampleName=Ops)
17/03/30 15:02:42 DEBUG impl.MetricsSystemImpl: UgiMetrics, User and group related metrics
17/03/30 15:02:43 DEBUG util.KerberosName: Kerberos krb5 configuration not found, setting default realm to empty
17/03/30 15:02:43 DEBUG security.Groups:  Creating new Groups object
17/03/30 15:02:43 DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
17/03/30 15:02:43 DEBUG util.NativeCodeLoader: Loaded the native-hadoop library
17/03/30 15:02:43 DEBUG security.JniBasedUnixGroupsMapping: Using JniBasedUnixGroupsMapping for Group resolution
17/03/30 15:02:43 DEBUG security.JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
17/03/30 15:02:43 DEBUG security.Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
17/03/30 15:02:43 DEBUG security.UserGroupInformation: hadoop login
17/03/30 15:02:43 DEBUG security.UserGroupInformation: hadoop login commit
17/03/30 15:02:43 DEBUG security.UserGroupInformation: using local user:UnixPrincipal: chinmay
17/03/30 15:02:43 DEBUG security.UserGroupInformation: Using user: "UnixPrincipal: chinmay" with name chinmay
17/03/30 15:02:43 DEBUG security.UserGroupInformation: User entry: "chinmay"
17/03/30 15:02:43 DEBUG security.UserGroupInformation: UGI loginUser:chinmay (auth:SIMPLE)
17/03/30 15:02:43 DEBUG hdfs.BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
17/03/30 15:02:43 DEBUG hdfs.BlockReaderLocal: dfs.client.read.shortcircuit = false
17/03/30 15:02:43 DEBUG hdfs.BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
17/03/30 15:02:43 DEBUG hdfs.BlockReaderLocal: dfs.domain.socket.path = 
17/03/30 15:02:43 DEBUG retry.RetryUtils: multipleLinearRandomRetry = null
17/03/30 15:02:43 DEBUG ipc.Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6f2297aa
17/03/30 15:02:43 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:43 DEBUG unix.DomainSocketWatcher: org.apache.hadoop.net.unix.DomainSocketWatcher$2@28f39e95: starting with interruptCheckPeriodMs = 60000
17/03/30 15:02:43 DEBUG util.PerformanceAdvisory: Both short-circuit local reads and UNIX domain socket are disabled.
17/03/30 15:02:43 DEBUG sasl.DataTransferSaslUtil: DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
17/03/30 15:02:43 DEBUG hdfs.DFSClient: /user/chinmay/test-location: masked=rw-r--r--
17/03/30 15:02:43 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:43 DEBUG ipc.Client: Connecting to localhost/127.0.0.1:9000
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay: starting, having connections 1
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #0
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #0
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: create took 54ms
17/03/30 15:02:43 DEBUG hdfs.DFSClient: computePacketChunkSize: src=/user/chinmay/test-location, chunkSize=516, chunksPerPacket=126, packetSize=65016
17/03/30 15:02:43 DEBUG hdfs.LeaseRenewer: Lease renewer daemon for [DFSClient_NONMAPREDUCE_1807150046_1] with renew id 1 started
1490866363700 : Writing... 1490866363695,0
1490866363701 : HSYNC DATA...
17/03/30 15:02:43 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=0, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:43 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=76 lastFlushOffset=0 createNewBlock=false
17/03/30 15:02:43 DEBUG hdfs.DFSClient: Queued packet 0
17/03/30 15:02:43 DEBUG hdfs.DFSClient: Allocating new block
17/03/30 15:02:43 DEBUG hdfs.DFSClient: Waiting for ack for: 0
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #1
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #1
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: addBlock took 4ms
17/03/30 15:02:43 DEBUG hdfs.DFSClient: pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]
17/03/30 15:02:43 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
17/03/30 15:02:43 DEBUG hdfs.DFSClient: Send buf size 131072
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #2
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #2
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: getServerDefaults took 1ms
17/03/30 15:02:43 DEBUG sasl.SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]
1490866363794 : Starting reader
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #3
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #3
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:43 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=0; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=0; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:43 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:43 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:43 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:43 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:43 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 76
17/03/30 15:02:43 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:43 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:43 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"3daCLghwcBfPmg+fOscxSSM4nqk2eXqfuNilXqE/\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:43 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:43 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:43 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #4
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #4
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 56ms
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:43 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
1490866363905 : Sleeping for 30000
1490866363905 : Waiting before reopen..
17/03/30 15:02:43 DEBUG hdfs.DFSClient: DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #5
17/03/30 15:02:43 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #5
17/03/30 15:02:43 DEBUG ipc.ProtobufRpcEngine: Call: fsync took 3ms
1490866364015 : Writing... 1490866364015,1
1490866364015 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=1, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=152 lastFlushOffset=76 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 1
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 1
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 1 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 152
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364117 : Writing... 1490866364117,2
1490866364117 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=2, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=228 lastFlushOffset=152 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 2
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 2
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 2 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 228
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364219 : Writing... 1490866364219,3
1490866364219 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=3, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=304 lastFlushOffset=228 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 3
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 3
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 3 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 304
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364321 : Writing... 1490866364321,4
1490866364321 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=4, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=380 lastFlushOffset=304 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 4
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 4
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 4 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 380
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #6
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #6
17/03/30 15:02:44 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:44 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:44 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:44 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:44 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:44 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:44 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:44 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"bX2LhpXYwuU/i9VPvlCP9zrZjlO1qwrHIEphFkVQ\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:44 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #7
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #7
17/03/30 15:02:44 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 4ms
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:44 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
17/03/30 15:02:44 DEBUG sasl.SaslDataTransferClient: SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]
1490866364423 : Writing... 1490866364423,5
1490866364423 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=5, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=456 lastFlushOffset=380 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 5
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 5
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 5 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 456
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 5 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364433 : 1490866364433,1490866363695,0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364435 : 1490866364435,1490866364015,1
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364436 : 1490866364436,1490866364117,2
1490866364436 : Waiting before reopen..
1490866364525 : Writing... 1490866364525,6
1490866364526 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=6, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=532 lastFlushOffset=456 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 6
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 6
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 6 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 532
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 6 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364627 : Writing... 1490866364627,7
1490866364627 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=7, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=608 lastFlushOffset=532 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 7
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 7
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 7 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 608
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 7 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364729 : Writing... 1490866364729,8
1490866364729 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=8, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=684 lastFlushOffset=608 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 8
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 8
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 8 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 684
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 8 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364831 : Writing... 1490866364831,9
1490866364831 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=9, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=760 lastFlushOffset=684 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 9
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 9
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 9 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 760
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 9 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866364933 : Writing... 1490866364933,10
1490866364933 : HFLUSH DATA...
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=10, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=836 lastFlushOffset=760 createNewBlock=false
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Queued packet 10
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Waiting for ack for: 10
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 10 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 836
17/03/30 15:02:44 DEBUG hdfs.DFSClient: DFSClient seqno: 10 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #8
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #8
17/03/30 15:02:44 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:44 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:44 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:44 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:44 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:44 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:44 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:44 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"sT9Bc5guDbbhaYfOB+4r8cILLluoKdHVtMvk4pgD\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:44 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:44 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #9
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #9
17/03/30 15:02:44 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 3ms
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:44 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:44 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364945 : 1490866364945,1490866364219,3
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364946 : 1490866364946,1490866364321,4
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364948 : 1490866364948,1490866364423,5
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364950 : 1490866364950,1490866364525,6
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364951 : 1490866364951,1490866364627,7
17/03/30 15:02:44 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866364953 : 1490866364953,1490866364729,8
1490866364953 : Waiting before reopen..
1490866365035 : Writing... 1490866365035,11
1490866365035 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=11, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=912 lastFlushOffset=836 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 11
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 11
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 11 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 912
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 11 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365137 : Writing... 1490866365136,12
1490866365137 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=12, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=988 lastFlushOffset=912 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 12
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 12
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 12 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 988
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 12 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365239 : Writing... 1490866365238,13
1490866365239 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=13, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=512
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1064 lastFlushOffset=988 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 13
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 13
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 13 offsetInBlock: 512 lastPacketInBlock: false lastByteOffsetInBlock: 1064
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 13 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365341 : Writing... 1490866365340,14
1490866365341 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=14, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1140 lastFlushOffset=1064 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 14
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 14
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 14 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1140
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 14 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365442 : Writing... 1490866365442,15
1490866365442 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=15, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1216 lastFlushOffset=1140 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 15
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 15
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 15 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1216
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 15 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #10
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #10
17/03/30 15:02:45 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:45 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:45 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:45 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:45 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:45 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:45 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:45 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"DkAXyCdSiQfAlTh7WlfkyfZ9JhjoaIE602ywhsD/\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:45 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #11
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #11
17/03/30 15:02:45 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 4ms
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:45 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365464 : 1490866365464,1490866364831,9
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365465 : 1490866365465,1490866364933,10
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365466 : 1490866365466,1490866365035,11
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365467 : 1490866365467,1490866365136,12
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365469 : 1490866365469,1490866365238,13
1490866365469 : Waiting before reopen..
1490866365547 : Writing... 1490866365547,16
1490866365548 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=16, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1292 lastFlushOffset=1216 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 16
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 16
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 16 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1292
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 16 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365649 : Writing... 1490866365649,17
1490866365649 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=17, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1368 lastFlushOffset=1292 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 17
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 17
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 17 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1368
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 17 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365751 : Writing... 1490866365751,18
1490866365751 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=18, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1444 lastFlushOffset=1368 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 18
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 18
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 18 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1444
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 18 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365853 : Writing... 1490866365853,19
1490866365853 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=19, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1520 lastFlushOffset=1444 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 19
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 19
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 19 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1520
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 19 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866365955 : Writing... 1490866365955,20
1490866365955 : HFLUSH DATA...
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=20, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1024
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1596 lastFlushOffset=1520 createNewBlock=false
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Queued packet 20
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Waiting for ack for: 20
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 20 offsetInBlock: 1024 lastPacketInBlock: false lastByteOffsetInBlock: 1596
17/03/30 15:02:45 DEBUG hdfs.DFSClient: DFSClient seqno: 20 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #12
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #12
17/03/30 15:02:45 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:45 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:45 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:45 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:45 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:45 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:45 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:45 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"K5UvqoY2FuyEFntTzs9waLWuYwHQPNFoWG25KS1r\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:45 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:45 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #13
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #13
17/03/30 15:02:45 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 5ms
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:45 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:45 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365981 : 1490866365981,1490866365340,14
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365982 : 1490866365982,1490866365442,15
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365984 : 1490866365984,1490866365547,16
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365986 : 1490866365986,1490866365649,17
17/03/30 15:02:45 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866365988 : 1490866365988,1490866365751,18
1490866365988 : Waiting before reopen..
1490866366057 : Writing... 1490866366057,21
1490866366057 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=21, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1672 lastFlushOffset=1596 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 21
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 21
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 21 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 1672
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 21 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366159 : Writing... 1490866366159,22
1490866366159 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=22, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1748 lastFlushOffset=1672 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 22
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 22
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 22 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 1748
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 22 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366261 : Writing... 1490866366260,23
1490866366261 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=23, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1824 lastFlushOffset=1748 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 23
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 23
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 23 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 1824
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 23 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366362 : Writing... 1490866366362,24
1490866366363 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=24, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1900 lastFlushOffset=1824 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 24
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 24
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 24 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 1900
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 24 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366465 : Writing... 1490866366464,25
1490866366465 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=25, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=1976 lastFlushOffset=1900 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 25
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 25
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 25 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 1976
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 25 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #14
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #14
17/03/30 15:02:46 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 1ms
17/03/30 15:02:46 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:46 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:46 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:46 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:46 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:46 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:46 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:46 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"v4KmT9QptR5toz/AGjC6lIE4dOifoOq2OuA/8EYm\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:46 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:46 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:46 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #15
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #15
17/03/30 15:02:46 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 11ms
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:46 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:46 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866366506 : 1490866366506,1490866365853,19
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866366507 : 1490866366507,1490866365955,20
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866366509 : 1490866366509,1490866366057,21
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866366510 : 1490866366510,1490866366159,22
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866366511 : 1490866366511,1490866366260,23
1490866366512 : Waiting before reopen..
1490866366566 : Writing... 1490866366566,26
1490866366566 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=26, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=1536
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2052 lastFlushOffset=1976 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 26
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 26
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 26 offsetInBlock: 1536 lastPacketInBlock: false lastByteOffsetInBlock: 2052
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 26 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366668 : Writing... 1490866366668,27
1490866366668 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=27, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2128 lastFlushOffset=2052 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 27
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 27
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 27 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2128
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 27 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366770 : Writing... 1490866366770,28
1490866366770 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=28, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2204 lastFlushOffset=2128 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 28
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 28
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 28 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2204
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 28 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366872 : Writing... 1490866366872,29
1490866366872 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=29, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2280 lastFlushOffset=2204 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 29
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 29
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 29 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2280
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 29 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866366974 : Writing... 1490866366974,30
1490866366974 : HFLUSH DATA...
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=30, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2356 lastFlushOffset=2280 createNewBlock=false
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Queued packet 30
17/03/30 15:02:46 DEBUG hdfs.DFSClient: Waiting for ack for: 30
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 30 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2356
17/03/30 15:02:46 DEBUG hdfs.DFSClient: DFSClient seqno: 30 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #16
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #16
17/03/30 15:02:47 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
17/03/30 15:02:47 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=0
  underConstruction=true
  blocks=[LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719; getBlockSize()=76; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:50010,DS-82872223-a4ff-4f01-9bcd-4007e39ae270,DISK]]}
  isLastBlockComplete=false}
17/03/30 15:02:47 DEBUG protocolPB.ClientDatanodeProtocolTranslatorPB: Connecting to datanode 127.0.0.1:50020 addr=/127.0.0.1:50020
17/03/30 15:02:47 DEBUG ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:47 DEBUG ipc.Client: The ping interval is 60000 ms.
17/03/30 15:02:47 DEBUG ipc.Client: Connecting to /127.0.0.1:50020
17/03/30 15:02:47 DEBUG security.UserGroupInformation: PrivilegedAction as:blk_1073775412_34719 (auth:SIMPLE) from:org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
17/03/30 15:02:47 DEBUG security.SaslRpcClient: Sending sasl message state: NEGOTIATE

17/03/30 15:02:47 DEBUG security.SaslRpcClient: Received SASL message state: NEGOTIATE
auths {
  method: "TOKEN"
  mechanism: "DIGEST-MD5"
  protocol: ""
  serverId: "default"
  challenge: "realm=\"default\",nonce=\"NRh2DeQUSLyt0xupiPrZoVwwuzcVlUX4E+OCBF9m\",qop=\"auth\",charset=utf-8,algorithm=md5-sess"
}
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:47 DEBUG security.SaslRpcClient: Get token info proto:interface org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB info:@org.apache.hadoop.security.token.TokenInfo(value=class org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector)
17/03/30 15:02:47 DEBUG security.SaslRpcClient: Use SIMPLE authentication for protocol ClientDatanodeProtocolPB
17/03/30 15:02:47 DEBUG security.SaslRpcClient: Sending sasl message state: INITIATE
auths {
  method: "SIMPLE"
  mechanism: ""
}

17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: starting, having connections 2
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 sending #17
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719 got value #17
17/03/30 15:02:47 DEBUG ipc.ProtobufRpcEngine: Call: getReplicaVisibleLength took 3ms
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: closed
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to /127.0.0.1:50020 from blk_1073775412_34719: stopped, remaining connections 1
17/03/30 15:02:47 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866367021 : 1490866367021,1490866366362,24
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866367023 : 1490866367022,1490866366464,25
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866367024 : 1490866367024,1490866366566,26
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866367025 : 1490866367025,1490866366668,27
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:50010
1490866367027 : 1490866367027,1490866366770,28
1490866367027 : Waiting before reopen..
1490866367076 : Writing... 1490866367076,31
1490866367076 : HFLUSH DATA...
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=31, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2432 lastFlushOffset=2356 createNewBlock=false
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 31
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Waiting for ack for: 31
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 31 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2432
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 31 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866367178 : Writing... 1490866367178,32
1490866367178 : HFLUSH DATA...
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=32, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2508 lastFlushOffset=2432 createNewBlock=false
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 32
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Waiting for ack for: 32
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 32 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2508
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 32 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866367280 : Writing... 1490866367280,33
1490866367280 : HFLUSH DATA...
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=33, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2048
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2584 lastFlushOffset=2508 createNewBlock=false
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 33
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Waiting for ack for: 33
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 33 offsetInBlock: 2048 lastPacketInBlock: false lastByteOffsetInBlock: 2584
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 33 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
1490866367382 : Writing... 1490866367382,34
1490866367382 : HFLUSH DATA...
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=34, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2560
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient flush(): bytesCurBlock=2660 lastFlushOffset=2584 createNewBlock=false
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 34
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Waiting for ack for: 34
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 34 offsetInBlock: 2560 lastPacketInBlock: false lastByteOffsetInBlock: 2660
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 34 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient writeChunk allocating new packet seqno=35, src=/user/chinmay/test-location, packetSize=65016, chunksPerPacket=126, bytesCurBlock=2560
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 35
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Queued packet 36
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Waiting for ack for: 36
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 35 offsetInBlock: 2560 lastPacketInBlock: false lastByteOffsetInBlock: 2660
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 35 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DataStreamer block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719 sending packet packet seqno: 36 offsetInBlock: 2660 lastPacketInBlock: true lastByteOffsetInBlock: 2660
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSClient seqno: 36 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
17/03/30 15:02:47 DEBUG hdfs.DFSClient: Closing old block BP-1348857850-127.0.1.1-1487931348321:blk_1073775412_34719
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay sending #18
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay got value #18
17/03/30 15:02:47 DEBUG ipc.ProtobufRpcEngine: Call: complete took 5ms
17/03/30 15:02:47 DEBUG ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:47 DEBUG ipc.Client: removing client from cache: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:47 DEBUG ipc.Client: stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@418dad71
17/03/30 15:02:47 DEBUG ipc.Client: Stopping client
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay: closed
17/03/30 15:02:47 DEBUG ipc.Client: IPC Client (696806398) connection to localhost/127.0.0.1:9000 from chinmay: stopped, remaining connections 0
1490866367484 : Writing... 1490866367484,35
1490866367484 : Current Thread is : 17
java.nio.channels.ClosedChannelException
	at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:1550)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:104)
	at java.io.OutputStream.write(OutputStream.java:75)
	at com.datatorrent.WriterImpl.write(WriterImpl.java:32)
	at com.datatorrent.RunTest$WriterThread.run(RunTest.java:122)
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1522)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:303)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:299)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:767)
	at com.datatorrent.ReaderImpl2.reopen(ReaderImpl2.java:61)
	at com.datatorrent.ReaderImpl2.read(ReaderImpl2.java:29)
	at com.datatorrent.RunTest$ReaderThread.run(RunTest.java:163)
17/03/30 15:02:47 DEBUG hdfs.DFSClient: DFSInputStream has been closed already
1490866367527 : Waiting before reopen..
